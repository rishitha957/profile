---
layout: post
title:  "Toxicity Problem"
date:   2024-01-02 18:08:39 +00:00
image: /thumbnails/toxicity.png
categories: project
subtitle: "Evaluating Toxicity in Modern Language Models: A Comparative Study"
# website: https://rishitha957.github.io/GreenComputeDoc/
# source-code: https://github.com/rishitha957/Sequence-Alignments
event: Guide - Dr. Anjali Field

---
Evaluating toxicity in large language models like Mistral-7b, Llama2-7b, and T5 by analyzing their responses to toxic prompts from the RealToxicityPrompts dataset, using both custom classification model and Perspective APIs for a detailed, fine-grained toxicity analysis.